---
layout: post
title: From the RoR world to the kingdom of express.js. Part 1.
---
I’ve been writing API-applications with Ruby on Rails for years and it satisfies me a lot.  Usual instruments that provides the desired usability are:

1. [Rails::API](https://github.com/rails-api/rails-api) is a bit more lightweight and faster Rails
2. PostgreSQL as a relational database
3. [Active Model Serializers](https://github.com/rails-api/active_model_serializers) for configuration the response's appearance.

This scope is a good fit for me. However, in these few-post series, I’ll look at the basics of obtaining rails-like `node.js` API instead. Probably you have a question: why? Because of several reasons.

Firstly, last year I’ve seen a greater rise of microservices popularity. Separating the large monolithic applications into microservices allows us to use not only rails applications.
Moreover, in some cases it would be better to avoid the such heavyweight framework as rails.
Plus, when you write a Node.js application, you're writing and learning Javascript. And the lifelong practice of learning is what makes us humans and our lives worthwhile.
So I decided to make a try and "translate" the familiar stack of technologies with Javascript. I want to stress that I don't have a lot of experience with `node.js` so this article should not be considered as a perfect example.

In this part I describe how to setup project that based on features of [express.js](http://expressjs.com/). As a first step I am going to create the simple CRUD logic for models that I gave the name `article`.

## 1. Create new express application

Let's start by installing `express-generator` (it installs `express` at the same time):

```bash
npm install -g express-generator
```

Once we’ve done, we can generate new application and then install dependencies:

```bash
express example-express-api
cd example-express-api
npm install
```

The server can be already fired by typing `npm start`, but for the better developing experience we really need to install some tool for the monitoring code changes. Without it the server has to be restarted manuallyeach time when the code was changed. There is [nodemon](https://github.com/remy/nodemon) that will restart automatically your node application.

```bash
npm install -g nodemon
```

And then switch lines in `package.json` to:

```javascript
"scripts": {
  "start": "nodemon ./bin/www"
}
```

Type `npm start` again and navigate to `http://localhost:3000/` in your browser. You should see the "Welcome to Express" text. Voila, we are ready to begin the actual development.

## 2. Using ES2015

Before we move on to the database details, let’s add ability to support the modern standard of JS &mdash; ES2015. It runs by transpiling new syntax that ES2015 brings into the browser supported one. To put it into the action let's install babel and preset for it.

```bash
npm install --save-dev babel-cli babel-preset-es2015
```

Then update the `start` script in the `package.json` file:

```javascript
"scripts": {
  "start": "nodemon ./bin/www --exec babel-node --presets es2015"
}
```

Because we have enabled `babel-cli` earlier we have access to the babel-node executable, which will transform all code before running it through nodemon.
Optionally, for the finishing touch we could update generated by the `express` files. Basically, we need three things to do:

* substitute the things like
`var routes = require('./routes/index')` to  `import routes from './routes/index'`
* use `let` instead of `var`
* introduce arrow functions. For example:
`function(req, res, next) {...}` transforms to `(req, res, next) => {...}`

## 3. Connect PostgreSQL to application

Rails has a really awesome migration system. It allows to evolve database schema over time. I want to use this mechanism in my js-app too. For these purposes I decided to use [pg-migrate](https://github.com/theoephraim/node-pg-migrate).

```bash
npm install -g node-pg-migrate --save
```

Then:

```bash
pg-migrate create create_articles
```

It generates new migration inside `migrations` folder. Fill it with the following code:

```javascript
exports.up = (pgm) => {
  pgm.createTable('articles', {
    id: { type: 'serial', primaryKey: true },
    title: { type: 'varchar(140)' },
    body: { type: 'text' },
    created_at: { type: 'timestamp' }
  });
};

exports.down = (pgm) => {
  pgm.drop('articles');
};
```

According to the documentaion for the successful migration we have to add `.env` in the root directory and include `require('dotenv').load();` at the top of `app.js` file. In `.env` I have to specify the database connection url by setting the environment variable `DATABASE_URL`. For instance:

```bash
DATABASE_URL=postgresql://localhost:5432/my_blog
```

Here I set up a simple structure of the articles table. The particular article consists two text fields (title and body) and one timestamp (created_at). It is time to create database with name `my_blog` in `psql` console and run migration command by entering `pg-migrate up`.

## 4. First couple of endpoints

Let's keep it simple by adding new route file `articles.js` inside `routes` directory. Two things to write inside `app.js`: new routes and specify base route. This is what the `app.js` should now contain:

```javascript
import articles from './routes/articles';
app.use('/articles', articles);
```
Now, let’s build first couple of endpoints: index and create. To make a request to database the connection pool should be initialized. It takes one argument presented url to database.

```javascript
import express from 'express';
import pg from 'pg';

let router = express.Router();

router.get('/', (req, res, next) => {
  pg.connect(process.env.DATABASE_URL, (err, client, done) => {
    let results = [];

    if (err) {
      done();
      return res.status(500).json({ success: false, data: err });
    }

    const query = client.query("SELECT * from articles ORDER BY id ASC");
    query.on('row', (row) => {
      results.push(row);
    });

    query.on('end', () => {
      done();
      return res.json(results);
    });
  });
});

module.exports = router;
```

For testing POST action I am using the POSTman extension for google chrome. We should send response via `x-www-form-urlencoded` format. Data are available through `res.body` attribute.

```javascript
router.post('/', (req, res, next) => {
  let data = { title: req.body.title, body: req.body.body };

  pg.connect(process.env.DATABASE_URL, (err, client, done) => {
    if (err) {
      done();
      return res.status(500).json({ success: false, data: err });
    }

    client.query("INSERT INTO articles(title, body, created_at) values($1, $2, $3)", [data.title, data.body, new Date()]);
    res.send("OK");
  });
});
```

## In-between conclusion

It seems to take much more time to string everything together in `express.js`. I guess the main reason relates to the lack of opionated structure. In next part I'm going to build remained endpoints to obtain the full CRUD interface and also polish routes by introducing controllers.
